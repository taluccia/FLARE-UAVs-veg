---
title: "UAV-Edge-RandomForest"
author: "Anna Talucci"
date: "8/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview

```{r eval=FALSE, include=FALSE}

install.packages(c('rsample', "randomForest", "ranger", "caret", "h2o"), lib='C:/Users/atalucci/Documents/R/win-library/3.6')


install.packages(c('pdp', "vip"), lib='C:/Users/atalucci/Documents/R/win-library/3.6')

install.packages(c('ROCR'), lib='C:/Users/atalucci/Documents/R/win-library/3.6')

install.packages(c('edarf'), lib='C:/Users/atalucci/Documents/R/win-library/3.6')

install.packages(c('Rtools'), lib='C:/Users/atalucci/Documents/R/win-library/3.6')

install.packages(c('magrittr'),
lib='C:/Users/atalucci/Documents/R/win-library/3.6')

install.packages(c('tidyverse'),
lib='C:/Users/atalucci/Documents/R/win-library/3.6')

install.packages(c('purrr'),
lib='C:/Users/atalucci/Documents/R/win-library/3.6')
```
reprtree
# Packages
```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
library(stringr)
library(cowplot)
library(rsample)      # data splitting 
library(randomForest) # basic implementation
library(ranger)       # a faster implementation of randomForest
library(caret)        # an aggregator package for performing many machine learning models
library(h2o)          # an extremely fast java-based platform
library(pdp)
library(vip)
library(gbm)
library(dismo)
library(purrr) # for looping
library(scales)
library(ROCR)
library(edarf)
library(magrittr)
```


# Field Data
```{r}
field_data = read.csv("../data/field_subset/field_data_all.csv")
```

```{r}
head(field_data)
```

```{r}
fd1 = field_data %>% dplyr::select(ID:aspect)
```


# UAV Data

```{r}
ndvi = read.csv("../data/extracted_data/2020-08-13_ndvi_all_pixels.csv", strip.white = TRUE)
```

```{r}
head(ndvi)
```
```{r}
ndvi1 = ndvi %>% dplyr::select(ndvi:plot_id) %>% rename(ID=plot_id)
```

# Combine NDVI and field data
```{r}
ndvi_fd = merge(fd1, ndvi1, by="ID")
head(ndvi_fd)
tail(ndvi_fd)
```

# Subset for edge analysis

```{r}
edge_data = ndvi_fd %>% filter(ID %in% c("CN_2001_2_-25", "CN_2001_1_-25", "BP_1983_2_-25a", "Alnus_1984_1_-25", "CN_2001_2_25", "CN_2001_1_25", "BP_1983_2_25", "Alnus_1984_1_25"))
```


# RF Edge

```{r}
head(mtcars)
set.seed(1353)
car_split <- initial_split(mtcars, prop = .7, strata = cyl, breaks=3)
train_data <- training(car_split)
test_data <- testing(car_split)

train_data
test_data
```



```{r}
set.seed(123)
edge_split <- initial_split(edge_data, prop = .7, strata = burn_unburn, breaks = 2)
edge_train <- training(edge_split)
edge_test  <- testing(edge_split)
```

```{r}
summary(edge_train)
summary(edge_test)
```

RandomForest(formula, ntree=n, mtry=FALSE, maxnodes = NULL)

```{r}
head(edge_train)
```


```{r}
edge_train_rf = randomForest::randomForest(as.factor(burn_unburn) ~ ndvi + up_flood + slope + burn_year, 
  data=edge_train,
  importance=TRUE)
```

```{r}
edge_predictions_rf <- predict(edge_train_rf, newdata = edge_test[,c("ndvi", "up_flood", "slope", "burn_year")])
confusionMatrix(edge_predictions_rf, edge_test$burn_unburn)
```

# Edge Only
## Fit RF model
https://www.listendata.com/2014/11/random-forest-with-r.html

```{r}
set.seed(123)
df_rf <- edge_data %>% na.omit()

rf1 = randomForest::randomForest(as.factor(burn_unburn) ~ ndvi + up_flood + slope + burn_year, 
  data=df_rf,
  ntree = 500,
  importance=TRUE)
```

```{r}
rf1
```

```{r}
df_rf <- df_rf %>% 
  mutate(predicted = predict(rf1))

# Get performance measures
confusionMatrix(df_rf$predicted, df_rf$burn_unburn)
```


```{r}
plot(rf1, main = "Error rate of random forest")
```

```{r}
varImpPlot(rf1, pch = 20, main = "Importance of Variables")
```

```{r}
# Variable importance plot (compare to randomForest::varImpPlot(boston_rf))
vip(rf1, bar = TRUE, horizontal = TRUE, size = 1.5) 
```



```{r}
partialPlot(rf1, pred.data = edge_data, x.var = "ndvi")
```
```{r}
# Switch to ggplot2
partial(rf1, pred.var = "ndvi", plot = TRUE,
              plot.engine = "ggplot2")
```

### Partial plots
https://bgreenwell.github.io/pdp/articles/pdp.html
https://www.r-bloggers.com/in-search-of-the-perfect-partial-plot/

```{r}
p2 <- rf1 %>%  # the %>% operator is read as "and then"
  partial(pred.var = "ndvi") %>%
  theme_light() +
  ggtitle("ggplot2-based PDP")
```



```{r}
pred1=predict(rf1,type = "prob")

perf = prediction(pred1[,2], edge_data$burn_unburn)
# 1. Area under curve
auc = performance(perf, "auc")
auc

# Calculate the AUC and print it to screen
auc.perf <- performance(perf, measure = "auc")
print(auc.perf@y.values)
# 2. True Positive and Negative Rate
pred3 = performance(perf, "tpr","fpr")
# 3. Plot the ROC curve
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
```


***
# burn v unburned
# Subset for edge analysis

```{r}
bu_data = ndvi_fd %>% filter(ID %in% c("CN_2001_2_-25", "CN_2001_1_-25", "BP_1983_2_-25a", "Alnus_1984_1_-25", "CN_2001_2_200", "CN_2001_1_200", "BP_1983_2_200", "Alnus_1984_1_200"))
```


```{r}
head(bu_data)

bu_data1 = bu_data %>% dplyr::select(burn_year:ndvi)
head(bu_data1)
```
```{r}
head(ndvi_fd)

ndvi_fd1 = ndvi_fd %>% filter(burn_unburn == "burned")
summary(ndvi_fd1)
```

```{r}
set.seed(123)
tr_split <- initial_split(ndvi_fd1, prop = .7, strata = plot_dis, breaks = 8)
tr_train <- training(tr_split)
tr_test  <- testing(tr_split)
```

```{r}
summary(tr_test)
```

```{r}
tr_test1 = tr_test %>% dplyr::select(burn_year:ndvi)
head(tr_test1)
```

## Fit RF model
https://www.listendata.com/2014/11/random-forest-with-r.html


```{r}
set.seed(123)
df_rf2 <- tr_test1 %>% na.omit()

fit_rf2 = randomForest::randomForest(ndvi ~ ., 
  data=df_rf2,
  ntree = 500,
  importance=TRUE)
```

```{r}
fit_rf2
```

```{r}
df_rf2 <- df_rf2 %>% 
  mutate(predicted = predict(fit_rf2))

# Get performance measures
confusionMatrix(df_rf2$predicted, df_rf2$burn_unburn)
```


```{r}
plot(fit_rf2, main = "Error rate of random forest")
```

```{r}
varImpPlot(fit_rf2, pch = 20, main = "Importance of Variables")
```

```{r}
# Variable importance plot (compare to randomForest::varImpPlot(boston_rf))
vip(fit_rf2, bar = TRUE, horizontal = TRUE, size = 1.5) 
```



```{r}
partialPlot(fit_rf2, pred.data = df_rf2, x.var = "ndvi")
```
```{r}
# Switch to ggplot2
partial(rf1, pred.var = "ndvi", plot = TRUE,
              plot.engine = "ggplot2")
```

### Partial plots
https://bgreenwell.github.io/pdp/articles/pdp.html
https://www.r-bloggers.com/in-search-of-the-perfect-partial-plot/

```{r}
p2 <- rf1 %>%  # the %>% operator is read as "and then"
  partial(pred.var = "ndvi") %>%
  theme_light() +
  ggtitle("ggplot2-based PDP")
```



```{r}
pred1=predict(rf1,type = "prob")

perf = prediction(pred1[,2], edge_data$burn_unburn)
# 1. Area under curve
auc = performance(perf, "auc")
auc

# Calculate the AUC and print it to screen
auc.perf <- performance(perf, measure = "auc")
print(auc.perf@y.values)
# 2. True Positive and Negative Rate
pred3 = performance(perf, "tpr","fpr")
# 3. Plot the ROC curve
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
```
